{"cells":[{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T03:21:18.648980Z","iopub.status.busy":"2024-05-01T03:21:18.648117Z","iopub.status.idle":"2024-05-01T03:21:19.842221Z","shell.execute_reply":"2024-05-01T03:21:19.840825Z","shell.execute_reply.started":"2024-05-01T03:21:18.648942Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n","from keras.optimizers import Adam"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>self_text</th>\n","      <th>subreddit</th>\n","      <th>created_time</th>\n","      <th>post_id</th>\n","      <th>author_name</th>\n","      <th>controversiality</th>\n","      <th>ups</th>\n","      <th>downs</th>\n","      <th>user_is_verified</th>\n","      <th>...</th>\n","      <th>user_link_karma</th>\n","      <th>user_comment_karma</th>\n","      <th>user_total_karma</th>\n","      <th>post_score</th>\n","      <th>post_self_text</th>\n","      <th>post_title</th>\n","      <th>post_upvote_ratio</th>\n","      <th>post_thumbs_ups</th>\n","      <th>post_total_awards_received</th>\n","      <th>post_created_time</th>\n","    </tr>\n","    <tr>\n","      <th>comment_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>l1ytazo</th>\n","      <td>1</td>\n","      <td>This is the major one, people keep downplaying...</td>\n","      <td>climatechange</td>\n","      <td>2024-04-30 17:15:22</td>\n","      <td>1cgmk4u</td>\n","      <td>rednib</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>157.0</td>\n","      <td>28686.0</td>\n","      <td>29023.0</td>\n","      <td>88</td>\n","      <td>There’s a lot of different impacts of climate ...</td>\n","      <td>What about climate change worries you the most...</td>\n","      <td>0.82</td>\n","      <td>88</td>\n","      <td>0</td>\n","      <td>2024-04-30 07:02:19</td>\n","    </tr>\n","    <tr>\n","      <th>l1yt78f</th>\n","      <td>1</td>\n","      <td>Totally agree. They profited off of our pollut...</td>\n","      <td>conspiracy</td>\n","      <td>2024-04-30 17:14:46</td>\n","      <td>1cgqzo1</td>\n","      <td>quiksilver10152</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>1002.0</td>\n","      <td>5513.0</td>\n","      <td>6586.0</td>\n","      <td>92</td>\n","      <td>NaN</td>\n","      <td>60 years of Failed Climate Change prediction. ...</td>\n","      <td>0.70</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>2024-04-30 11:56:09</td>\n","    </tr>\n","    <tr>\n","      <th>l1yt2mc</th>\n","      <td>1</td>\n","      <td>I honestly believe the truth always lies somew...</td>\n","      <td>conspiracy</td>\n","      <td>2024-04-30 17:14:01</td>\n","      <td>1cgqzo1</td>\n","      <td>eco78</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>772.0</td>\n","      <td>33795.0</td>\n","      <td>34775.0</td>\n","      <td>92</td>\n","      <td>NaN</td>\n","      <td>60 years of Failed Climate Change prediction. ...</td>\n","      <td>0.70</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>2024-04-30 11:56:09</td>\n","    </tr>\n","    <tr>\n","      <th>l1yt0bm</th>\n","      <td>1</td>\n","      <td>lol, Zuck &amp;amp; the other billionaires are jus...</td>\n","      <td>climatechange</td>\n","      <td>2024-04-30 17:13:39</td>\n","      <td>1cgmk4u</td>\n","      <td>rednib</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>157.0</td>\n","      <td>28686.0</td>\n","      <td>29023.0</td>\n","      <td>88</td>\n","      <td>There’s a lot of different impacts of climate ...</td>\n","      <td>What about climate change worries you the most...</td>\n","      <td>0.82</td>\n","      <td>88</td>\n","      <td>0</td>\n","      <td>2024-04-30 07:02:19</td>\n","    </tr>\n","    <tr>\n","      <th>l1yszhw</th>\n","      <td>1</td>\n","      <td>&amp;gt; Global average surface air temps exceeded...</td>\n","      <td>conspiracy</td>\n","      <td>2024-04-30 17:13:31</td>\n","      <td>1cgqzo1</td>\n","      <td>Steve-lrwin</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>13609.0</td>\n","      <td>30294.0</td>\n","      <td>43903.0</td>\n","      <td>92</td>\n","      <td>NaN</td>\n","      <td>60 years of Failed Climate Change prediction. ...</td>\n","      <td>0.70</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>2024-04-30 11:56:09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["            score                                          self_text  \\\n","comment_id                                                             \n","l1ytazo         1  This is the major one, people keep downplaying...   \n","l1yt78f         1  Totally agree. They profited off of our pollut...   \n","l1yt2mc         1  I honestly believe the truth always lies somew...   \n","l1yt0bm         1  lol, Zuck &amp; the other billionaires are jus...   \n","l1yszhw         1  &gt; Global average surface air temps exceeded...   \n","\n","                subreddit        created_time  post_id      author_name  \\\n","comment_id                                                                \n","l1ytazo     climatechange 2024-04-30 17:15:22  1cgmk4u           rednib   \n","l1yt78f        conspiracy 2024-04-30 17:14:46  1cgqzo1  quiksilver10152   \n","l1yt2mc        conspiracy 2024-04-30 17:14:01  1cgqzo1            eco78   \n","l1yt0bm     climatechange 2024-04-30 17:13:39  1cgmk4u           rednib   \n","l1yszhw        conspiracy 2024-04-30 17:13:31  1cgqzo1      Steve-lrwin   \n","\n","            controversiality  ups  downs  user_is_verified  ...  \\\n","comment_id                                                  ...   \n","l1ytazo                    0    1      0              True  ...   \n","l1yt78f                    0    1      0              True  ...   \n","l1yt2mc                    0    1      0              True  ...   \n","l1yt0bm                    0    1      0              True  ...   \n","l1yszhw                    0    1      0              True  ...   \n","\n","           user_link_karma  user_comment_karma  user_total_karma  post_score  \\\n","comment_id                                                                     \n","l1ytazo              157.0             28686.0           29023.0          88   \n","l1yt78f             1002.0              5513.0            6586.0          92   \n","l1yt2mc              772.0             33795.0           34775.0          92   \n","l1yt0bm              157.0             28686.0           29023.0          88   \n","l1yszhw            13609.0             30294.0           43903.0          92   \n","\n","                                               post_self_text  \\\n","comment_id                                                      \n","l1ytazo     There’s a lot of different impacts of climate ...   \n","l1yt78f                                                   NaN   \n","l1yt2mc                                                   NaN   \n","l1yt0bm     There’s a lot of different impacts of climate ...   \n","l1yszhw                                                   NaN   \n","\n","                                                   post_title  \\\n","comment_id                                                      \n","l1ytazo     What about climate change worries you the most...   \n","l1yt78f     60 years of Failed Climate Change prediction. ...   \n","l1yt2mc     60 years of Failed Climate Change prediction. ...   \n","l1yt0bm     What about climate change worries you the most...   \n","l1yszhw     60 years of Failed Climate Change prediction. ...   \n","\n","            post_upvote_ratio post_thumbs_ups post_total_awards_received  \\\n","comment_id                                                                 \n","l1ytazo                  0.82              88                          0   \n","l1yt78f                  0.70              92                          0   \n","l1yt2mc                  0.70              92                          0   \n","l1yt0bm                  0.82              88                          0   \n","l1yszhw                  0.70              92                          0   \n","\n","             post_created_time  \n","comment_id                      \n","l1ytazo    2024-04-30 07:02:19  \n","l1yt78f    2024-04-30 11:56:09  \n","l1yt2mc    2024-04-30 11:56:09  \n","l1yt0bm    2024-04-30 07:02:19  \n","l1yszhw    2024-04-30 11:56:09  \n","\n","[5 rows x 23 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["\n","reddit_df = pd.read_csv('input/reddit_opinion_climate_change.csv',index_col=['comment_id'], parse_dates=['created_time', 'post_created_time'])\n","reddit_df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['climatechange' 'conspiracy' 'climate' 'climateskeptics' 'science'\n"," 'ClimateShitposting' 'worldnews' 'Futurology' 'europe' 'energy'\n"," 'environment' 'changemyview' 'ClimateActionPlan' 'news'\n"," 'EverythingScience' 'politics' 'canada' 'GlobalClimateChange'\n"," 'unitedkingdom' 'ClimateOffensive' 'ClimateMemes' 'CitizensClimateLobby'\n"," 'ClimateCO' 'Climate_Nuremberg' 'climate_discussion' 'climate_science']\n"]}],"source":["df_subreddits = reddit_df['subreddit'].unique()\n","print(df_subreddits)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# filter reddit data to include a few interesting subreddits and limit amount of reddit data\n","filtered_reddit_df = reddit_df.loc[reddit_df['subreddit'].isin(['climatechange', 'climate', 'climateskeptics'])]"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# get the text data for the comment and clean up anything missing\n","reddit_text_data = filtered_reddit_df.self_text\n","# remove potential nulls\n","reddit_text_data = reddit_text_data.fillna('')\n","# Convert all entries to strings (in case there are any non-string entries)\n","reddit_text_data = reddit_text_data.astype(str)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-01T03:31:12.728756Z","iopub.status.busy":"2024-05-01T03:31:12.728365Z","iopub.status.idle":"2024-05-01T03:31:12.992636Z","shell.execute_reply":"2024-05-01T03:31:12.991260Z","shell.execute_reply.started":"2024-05-01T03:31:12.728724Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>message</th>\n","      <th>tweetid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>@tiniebeany climate change is an interesting h...</td>\n","      <td>792927353886371840</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n","      <td>793124211518832641</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n","      <td>793124402388832256</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>RT @Mick_Fanning: Just watched this amazing do...</td>\n","      <td>793124635873275904</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n","      <td>793125156185137153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment                                            message  \\\n","0         -1  @tiniebeany climate change is an interesting h...   \n","1          1  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n","2          1  Fabulous! Leonardo #DiCaprio's film on #climat...   \n","3          1  RT @Mick_Fanning: Just watched this amazing do...   \n","4          2  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n","\n","              tweetid  \n","0  792927353886371840  \n","1  793124211518832641  \n","2  793124402388832256  \n","3  793124635873275904  \n","4  793125156185137153  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["twitter_df = pd.read_csv('input/twitter_sentiment_data.csv')\n","twitter_df.head()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# replacing -1 with 3 for LSTM are not working with negative values\n","twitter_df['sentiment'] = twitter_df['sentiment'].replace(-1, 3)\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["0    @tiniebeany climate change is an interesting h...\n","1    RT @NatGeoChannel: Watch #BeforeTheFlood right...\n","2    Fabulous! Leonardo #DiCaprio's film on #climat...\n","3    RT @Mick_Fanning: Just watched this amazing do...\n","4    RT @cnalive: Pranita Biswasi, a Lutheran from ...\n","Name: message, dtype: object"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["twitter_text_data = twitter_df['message']\n","twitter_text_data.head()"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["comment_id\n","l1ytazo    This is the major one, people keep downplaying...\n","l1yt0bm    lol, Zuck &amp; the other billionaires are jus...\n","l1ysptw                   Laughable at this point really ...\n","l1ysmdg    Electricity is a utility; it's not a standard ...\n","l1ysiva    # Tesla Model S emits more lifetime CO2 in US ...\n","Name: self_text, dtype: object"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["reddit_text_data.head()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# Combine the Reddit and Twitter data\n","combined_text_data = pd.concat([reddit_text_data, twitter_text_data], ignore_index=True)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["#Tokenization -- fit the tokenizer on the combined twitter data and reddit data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(combined_text_data)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 160174 unique tokens.\n"]}],"source":["#Tokenization -- converting the tweets into numerical tokens that can be processed by the model\n","sequences = tokenizer.texts_to_sequences(twitter_text_data)\n","word_index = tokenizer.word_index\n","print(\"Found %s unique tokens.\" % len(word_index))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# Padding sequences\n","max_sequence_length = 100  # Max sequence length (you may adjust this based on your data)\n","data = pad_sequences(sequences, maxlen=max_sequence_length)\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["labels = twitter_df['sentiment']"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# Define LSTM model\n","lstm_model = Sequential()\n","lstm_model.add(Embedding(len(word_index) + 1, 128, input_length=max_sequence_length))\n","lstm_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","lstm_model.add(Dense(4, activation='softmax'))\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# Compile LSTM model\n","lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","275/275 [==============================] - 152s 542ms/step - loss: 0.8645 - accuracy: 0.6495 - val_loss: 0.6878 - val_accuracy: 0.7270\n","Epoch 2/10\n","275/275 [==============================] - 155s 562ms/step - loss: 0.4532 - accuracy: 0.8281 - val_loss: 0.6648 - val_accuracy: 0.7404\n","Epoch 3/10\n","275/275 [==============================] - 151s 548ms/step - loss: 0.1720 - accuracy: 0.9408 - val_loss: 0.7612 - val_accuracy: 0.7211\n","Epoch 4/10\n","275/275 [==============================] - 154s 561ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.9564 - val_accuracy: 0.7026\n","Epoch 5/10\n","275/275 [==============================] - 157s 572ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 1.1583 - val_accuracy: 0.7225\n","Epoch 6/10\n","275/275 [==============================] - 154s 560ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 1.2725 - val_accuracy: 0.7068\n","Epoch 7/10\n","275/275 [==============================] - 174s 632ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.2459 - val_accuracy: 0.7191\n","Epoch 8/10\n","275/275 [==============================] - 166s 604ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 1.2848 - val_accuracy: 0.7110\n","Epoch 9/10\n","275/275 [==============================] - 169s 614ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.3564 - val_accuracy: 0.7096\n","Epoch 10/10\n","275/275 [==============================] - 161s 586ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.4298 - val_accuracy: 0.7110\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x142a9a210>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["# Train LSTM model\n","lstm_model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["275/275 [==============================] - 5s 17ms/step - loss: 1.3377 - accuracy: 0.7082\n","Test Loss: 1.3376867771148682\n","Test Accuracy: 0.7081578969955444\n"]}],"source":["# Evaluate the model on the test data\n","loss, accuracy = lstm_model.evaluate(X_test, y_test)\n","\n","# Print the test loss and accuracy\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: Found word index 160174 but the model's vocabulary size is 81449\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-14 19:21:01.579803: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: indices[31,99] = 114950 is not in [0, 81449)\n","\t [[{{node sequential/embedding/embedding_lookup}}]]\n"]},{"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node 'sequential/embedding/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/jt/_ss6h9nd2l7g209tcwt1fr6h0000gn/T/ipykernel_73659/2971589738.py\", line 9, in <module>\n      predictions = lstm_model.predict(reddit_data_prediction)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential/embedding/embedding_lookup'\nindices[31,99] = 114950 is not in [0, 81449)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_19850]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Found word index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreddit_data_prediction\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms vocabulary size is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreddit_data_prediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# type(predictions)\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/embedding/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/jt/_ss6h9nd2l7g209tcwt1fr6h0000gn/T/ipykernel_73659/2971589738.py\", line 9, in <module>\n      predictions = lstm_model.predict(reddit_data_prediction)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/tf/lib/python3.11/site-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential/embedding/embedding_lookup'\nindices[31,99] = 114950 is not in [0, 81449)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_19850]"]}],"source":["# Convert reddit_text_data to sequences\n","reddit_sequences = tokenizer.texts_to_sequences(reddit_text_data)\n","\n","reddit_data_prediction = pad_sequences(reddit_sequences, maxlen=max_sequence_length)\n","\n","# Check if any indices are out of range\n","embedding_layer = lstm_model.layers[0]\n","vocab_size = embedding_layer.get_weights()[0].shape[0]\n","if reddit_data_prediction.max() >= vocab_size:\n","    print(f\"Error: Found word index {reddit_data_prediction.max()} but the model's vocabulary size is {vocab_size}\")\n","\n","# Predict\n","predictions = lstm_model.predict(reddit_data_prediction)\n","# type(predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert predictions to class labels\n","predicted_labels = np.argmax(predictions, axis=1)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8403472,"datasetId":4029865,"sourceId":8274407,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
